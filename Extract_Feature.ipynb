{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extrac Features"
      ],
      "metadata": {
        "id": "fCFX0aYBa86h"
      },
      "id": "fCFX0aYBa86h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เเก้ PATH ตรงนี้"
      ],
      "metadata": {
        "id": "C68OPGkwz6is"
      },
      "id": "C68OPGkwz6is"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skimage.feature import hog\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import cv2, glob, random, math, numpy as np, dlib, itertools\n",
        "import os\n",
        "import random\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn import linear_model\n",
        "\n",
        "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/drive/MyDrive/Colab Notebooks/shape_predictor_68_face_landmarks.dat\") \n",
        "\n",
        "def list_images(basePath, contains=None):\n",
        "    return list_files(basePath, validExts=image_types, contains=contains)\n",
        "\n",
        "\n",
        "def list_files(basePath, validExts=None, contains=None):\n",
        "    # loop over the directory structure\n",
        "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
        "        # loop over the filenames in the current directory\n",
        "        for filename in filenames:\n",
        "            # if the contains string is not none and the filename does not contain\n",
        "            # the supplied string, then ignore the file\n",
        "            if contains is not None and filename.find(contains) == -1:\n",
        "                continue\n",
        "\n",
        "            # determine the file extension of the current file\n",
        "            ext = filename[filename.rfind(\".\"):].lower()\n",
        "\n",
        "            # check to see if the file is an image and should be processed\n",
        "            if validExts is None or ext.endswith(validExts):\n",
        "                # construct the path to the image and yield it\n",
        "                imagePath = os.path.join(rootDir, filename)\n",
        "                yield imagePath\n",
        "\n",
        "imagePaths = list(list_images('/content/drive/MyDrive/Colab Notebooks/images2'))"
      ],
      "metadata": {
        "id": "IWR2ZlJtbA5_"
      },
      "id": "IWR2ZlJtbA5_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET features and labes"
      ],
      "metadata": {
        "id": "he5wnoVukMBK"
      },
      "id": "he5wnoVukMBK"
    },
    {
      "cell_type": "code",
      "source": [
        "def colortogray(im):\n",
        "    image = cv2.imread(im)\n",
        "    imgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return imgray\n",
        "\n",
        "def feat_lab_HOG(imagePaths):\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for imagePath in imagePaths:\n",
        "        im = colortogray(imagePath)\n",
        "        \n",
        "        fd1 =  hog(im, orientations=7, pixels_per_cell=(8, 8),cells_per_block=(4, 4),block_norm= 'L2-Hys' ,transform_sqrt = False)\n",
        "\n",
        "        label = imagePath.split(os.path.sep)[-2]\n",
        "        labels.append(label)\n",
        "        features.append(fd1)\n",
        "\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "    return features,labels\n",
        "\n",
        "def feat_lab_LAND(imagePaths):\n",
        "      features = []\n",
        "      labels = []\n",
        "      for imagePath in imagePaths:\n",
        "        im = colortogray(imagePath)\n",
        "        clahe_image = clahe.apply(im)\n",
        "        landmarks_vectorised = get_landmarks(clahe_image)\n",
        "        if landmarks_vectorised == \"error\":\n",
        "          pass\n",
        "        else:\n",
        "          label = imagePath.split(os.path.sep)[-2]\n",
        "          labels.append(label)\n",
        "          features.append(landmarks_vectorised)\n",
        "      features = np.array(features)\n",
        "      labels = np.array(labels)\n",
        "      return features,labels\n",
        "\n",
        "def feat_lab_LBP(imagePaths):\n",
        "      features = []\n",
        "      labels = []\n",
        "      for imagePath in imagePaths:\n",
        "        im = colortogray(imagePath)\n",
        "        lbp_featured = lbp_feature(im)\n",
        "        if lbp_featured == \"error\":\n",
        "          pass\n",
        "        else:\n",
        "          label = imagePath.split(os.path.sep)[-2]\n",
        "          labels.append(label)\n",
        "          features.append(lbp_featured)\n",
        "      features = np.array(features)\n",
        "      labels = np.array(labels)\n",
        "      return features,labels\n",
        "\n",
        "def feat_lab_HLAC(imagePaths):\n",
        "      features = []\n",
        "      labels = []\n",
        "      for imagePath in imagePaths:\n",
        "        im = colortogray(imagePath)\n",
        "        _, img = cv2.threshold(im, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "        hlac_featured = calc_hlac_dev(img)\n",
        "        if hlac_featured == \"error\":\n",
        "          pass\n",
        "        else:\n",
        "          label = imagePath.split(os.path.sep)[-2]\n",
        "          labels.append(label)\n",
        "          features.append(hlac_featured)\n",
        "      features = np.array(features)\n",
        "      labels = np.array(labels)\n",
        "      return features,labels\n",
        "\n",
        "def feat_lab_GABOR(imagePaths):\n",
        "      features = []\n",
        "      labels = []\n",
        "      for imagePath in imagePaths:\n",
        "        im = colortogray(imagePath)\n",
        "        gabor_featured = get_gabor(im)\n",
        "        if gabor_featured == \"error\":\n",
        "          pass\n",
        "        else:\n",
        "          label = imagePath.split(os.path.sep)[-2]\n",
        "          labels.append(label)\n",
        "          features.append(gabor_featured)\n",
        "      features = np.array(features)\n",
        "      labels = np.array(labels)\n",
        "      return features,labels"
      ],
      "metadata": {
        "id": "QM7uPOKSbObP"
      },
      "id": "QM7uPOKSbObP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_landmarks(image):\n",
        "    detections = detector(image, 1)\n",
        "    for k,d in enumerate(detections): #For all detected face instances individually\n",
        "        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\n",
        "        xlist = []\n",
        "        ylist = []\n",
        "        for i in range(1,68): #Store X and Y coordinates in two lists\n",
        "            xlist.append(float(shape.part(i).x))\n",
        "            ylist.append(float(shape.part(i).y))\n",
        "            \n",
        "        xmean = np.mean(xlist) #Get the mean of both axes to determine centre of gravity\n",
        "        ymean = np.mean(ylist)\n",
        "        xcentral = [(x-xmean) for x in xlist] #get distance between each point and the central point in both axes\n",
        "        ycentral = [(y-ymean) for y in ylist]\n",
        "\n",
        "        if xlist[26] == xlist[29]: #If x-coordinates of the set are the same, the angle is 0, catch to prevent 'divide by 0' error in function\n",
        "            anglenose = 0\n",
        "        else:\n",
        "            anglenose = int(math.atan((ylist[26]-ylist[29])/(xlist[26]-xlist[29]))*180/math.pi)\n",
        "\n",
        "        if anglenose < 0:\n",
        "            anglenose += 90\n",
        "        else:\n",
        "            anglenose -= 90\n",
        "\n",
        "        landmarks_vectorised = []\n",
        "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
        "            landmarks_vectorised.append(x)\n",
        "            landmarks_vectorised.append(y)\n",
        "            meannp = np.asarray((ymean,xmean))\n",
        "            coornp = np.asarray((z,w))\n",
        "            dist = np.linalg.norm(coornp-meannp)\n",
        "            anglerelative = (math.atan((z-ymean)/(w-xmean))*180/math.pi) - anglenose\n",
        "            landmarks_vectorised.append(dist)\n",
        "            landmarks_vectorised.append(anglerelative)\n",
        "\n",
        "        if len(detections) < 1: \n",
        "          landmarks_vectorised = \"error\"\n",
        "    return landmarks_vectorised"
      ],
      "metadata": {
        "id": "BwWMBNwLesJy"
      },
      "id": "BwWMBNwLesJy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LBP"
      ],
      "metadata": {
        "id": "tPiUdoj9hn79"
      },
      "id": "tPiUdoj9hn79"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def get_pixel(img, center, x, y):\n",
        "    new_value = 0\n",
        "    try:\n",
        "        if img[x][y] >= center:\n",
        "            new_value = 1\n",
        "    except:\n",
        "        pass\n",
        "    return new_value\n",
        "\n",
        "def lbp_calculated_pixel(img, x, y):\n",
        "    '''\n",
        "\n",
        "     64 | 128 |   1\n",
        "    ----------------\n",
        "     32 |   0 |   2\n",
        "    ----------------\n",
        "     16 |   8 |   4    \n",
        "\n",
        "    '''    \n",
        "    center = img[x][y]\n",
        "    val_ar = []\n",
        "    val_ar.append(get_pixel(img, center, x-1, y+1))     # top_right\n",
        "    val_ar.append(get_pixel(img, center, x, y+1))       # right\n",
        "    val_ar.append(get_pixel(img, center, x+1, y+1))     # bottom_right\n",
        "    val_ar.append(get_pixel(img, center, x+1, y))       # bottom\n",
        "    val_ar.append(get_pixel(img, center, x+1, y-1))     # bottom_left\n",
        "    val_ar.append(get_pixel(img, center, x, y-1))       # left\n",
        "    val_ar.append(get_pixel(img, center, x-1, y-1))     # top_left\n",
        "    val_ar.append(get_pixel(img, center, x-1, y))       # top\n",
        "    \n",
        "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "    val = 0\n",
        "    for i in range(len(val_ar)):\n",
        "        val += val_ar[i] * power_val[i]\n",
        "    return val    \n",
        "\n",
        "def show_output(output_list):\n",
        "    output_list_len = len(output_list)\n",
        "    figure = plt.figure()\n",
        "    for i in range(output_list_len):\n",
        "        current_dict = output_list[i]\n",
        "        current_img = current_dict[\"img\"]\n",
        "        current_xlabel = current_dict[\"xlabel\"]\n",
        "        current_ylabel = current_dict[\"ylabel\"]\n",
        "        current_xtick = current_dict[\"xtick\"]\n",
        "        current_ytick = current_dict[\"ytick\"]\n",
        "        current_title = current_dict[\"title\"]\n",
        "        current_type = current_dict[\"type\"]\n",
        "        current_plot = figure.add_subplot(1, output_list_len, i+1)\n",
        "        if current_type == \"gray\":\n",
        "            current_plot.imshow(current_img, cmap = plt.get_cmap('gray'))\n",
        "            current_plot.set_title(current_title)\n",
        "            current_plot.set_xticks(current_xtick)\n",
        "            current_plot.set_yticks(current_ytick)\n",
        "            current_plot.set_xlabel(current_xlabel)\n",
        "            current_plot.set_ylabel(current_ylabel)\n",
        "        elif current_type == \"histogram\":\n",
        "            current_plot.plot(current_img, color = \"black\")\n",
        "            current_plot.set_xlim([0,260])\n",
        "            current_plot.set_title(current_title)\n",
        "            current_plot.set_xlabel(current_xlabel)\n",
        "            current_plot.set_ylabel(current_ylabel)            \n",
        "            ytick_list = [int(i) for i in current_plot.get_yticks()]\n",
        "            current_plot.set_yticklabels(ytick_list,rotation = 90)\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "def lbp_feature(image):\n",
        "    img_bgr = image\n",
        "    \n",
        "    height, width = img_bgr.shape\n",
        "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
        "    for i in range(0, height):\n",
        "        for j in range(0, width):\n",
        "             img_lbp[i, j] = lbp_calculated_pixel(image, i, j)\n",
        "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
        "    return hist_lbp"
      ],
      "metadata": {
        "id": "nu_JjkSWhmoi"
      },
      "id": "nu_JjkSWhmoi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HLAC"
      ],
      "metadata": {
        "id": "r2R5auZRjpNe"
      },
      "id": "r2R5auZRjpNe"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "def calc_chlac_dev(div_data, masks, mask_n):\n",
        "    chlacs = np.array([])\n",
        "    for m, mn in zip(masks, mask_n):\n",
        "        chlacs = np.append(\n",
        "            chlacs, (np.sum(np.sum(np.logical_and(m, div_data), axis=1) == mn))\n",
        "        )\n",
        "    return chlacs\n",
        "\n",
        "\n",
        "# old version, too slow\n",
        "def calc_chlac(div_data, masks, mask_n):\n",
        "    chlacs = []\n",
        "    for m, mn in zip(masks, mask_n):\n",
        "        logic = np.logical_and(m, div_data)\n",
        "        logic_sum = np.sum(logic, axis=1)\n",
        "        chlacs.append(np.sum(logic_sum == int(mn)))\n",
        "    return np.array(chlacs)\n",
        "\n",
        "\n",
        "def split2boxel(data):\n",
        "    x, y = data[0].shape\n",
        "    d = 3\n",
        "    li = []\n",
        "    # 最外周は外してnp.whereを実行\n",
        "    # np.whereは切り出したndarrayに対して条件に一致するインデックスを返す\n",
        "    idxs_x, idxs_y = np.where(data[1, 1:-1, 1:-1] == 255)\n",
        "    # i, jは切り出すボクセルの左上隅のインデックスを表す\n",
        "    for i, j in zip(idxs_x, idxs_y):\n",
        "        li.append(data[:, i: i + d, j: j + d])\n",
        "    div_data = np.array(li).reshape([len(li), 27]).astype(np.int32)\n",
        "\n",
        "    return div_data\n",
        "\n",
        "\n",
        "# old version, too slow\n",
        "def split2boxel_(data):\n",
        "    x, y = data[0].shape\n",
        "    d = 3\n",
        "    li = []\n",
        "    for i in range(x - 2):\n",
        "        for j in range(y - 2):\n",
        "            if data[1, i + 1, j + 1] != 0:\n",
        "                li.append(data[:, i: i + d, j: j + d])\n",
        "    div_data_ = np.array(li).reshape([len(li), 27]).astype(np.int32)\n",
        "\n",
        "    return div_data_\n",
        "\n",
        "\n",
        "def prepare_masks_chlac(mask_filepath):\n",
        "    data = pd.read_csv(mask_filepath, header=None, index_col=0)\n",
        "    N_mask = data.shape[0]\n",
        "\n",
        "    masks = []\n",
        "    for j in range(N_mask):\n",
        "        mask = np.zeros([3, 3, 3])  # voxel\n",
        "        _ = []\n",
        "        for i in range(3):\n",
        "            if data.iloc[j, i] == \"x\":\n",
        "                _.append([])\n",
        "            elif data.iloc[j, i] != \"x\":\n",
        "                if len(data.iloc[j, i]) == 1:\n",
        "                    _.append([data.iloc[j, i]])\n",
        "                else:\n",
        "                    _.append(data.iloc[j, i].split(\",\"))\n",
        "\n",
        "        for i in range(3):\n",
        "            if len(_[i]) == 0:\n",
        "                continue\n",
        "            for m in _[i]:\n",
        "                if m == \"a\":\n",
        "                    mask[0, i, 0] = 1\n",
        "                elif m == \"b\":\n",
        "                    mask[1, i, 0] = 1\n",
        "                elif m == \"c\":\n",
        "                    mask[2, i, 0] = 1\n",
        "                elif m == \"d\":\n",
        "                    mask[0, i, 1] = 1\n",
        "                elif m == \"e\":\n",
        "                    mask[1, i, 1] = 1\n",
        "                elif m == \"f\":\n",
        "                    mask[2, i, 1] = 1\n",
        "                elif m == \"g\":\n",
        "                    mask[0, i, 2] = 1\n",
        "                elif m == \"h\":\n",
        "                    mask[1, i, 2] = 1\n",
        "                elif m == \"i\":\n",
        "                    mask[2, i, 2] = 1\n",
        "        mask = mask.reshape(mask.shape[0] * mask.shape[1] * mask.shape[2])\n",
        "        masks.append(mask)\n",
        "    masks = np.array(masks)\n",
        "    mask_n = np.array(masks).sum(axis=1)\n",
        "\n",
        "    return masks, mask_n\n",
        "\n",
        "\n",
        "def read_testdata():\n",
        "    imgs = 255 * np.array(\n",
        "        [\n",
        "            [\n",
        "                [1, 0, 1, 1, 0, 1],\n",
        "                [1, 1, 0, 0, 1, 1],\n",
        "                [0, 0, 1, 0, 0, 0],\n",
        "                [1, 1, 1, 1, 1, 0],\n",
        "                [1, 1, 1, 1, 1, 1],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "            ],\n",
        "            [\n",
        "                [1, 1, 1, 0, 0, 1],\n",
        "                [1, 1, 1, 0, 0, 1],\n",
        "                [0, 1, 1, 0, 1, 0],\n",
        "                [1, 1, 0, 1, 1, 0],\n",
        "                [1, 1, 1, 0, 0, 0],\n",
        "                [0, 1, 0, 0, 0, 0],\n",
        "            ],\n",
        "            [\n",
        "                [1, 1, 0, 0, 1, 1],\n",
        "                [0, 0, 1, 1, 0, 1],\n",
        "                [0, 1, 0, 1, 0, 1],\n",
        "                [1, 1, 1, 0, 0, 0],\n",
        "                [1, 0, 0, 1, 0, 0],\n",
        "                [0, 1, 1, 0, 1, 1],\n",
        "            ],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def calc_hlac_dev(img, dim=3):\n",
        "    masks_origin = [\n",
        "        \"000010000\",\n",
        "        \"000011000\",\n",
        "        \"001010000\",\n",
        "        \"010010000\",\n",
        "        \"100010000\",\n",
        "        \"000111000\",\n",
        "        \"001010100\",\n",
        "        \"010010010\",\n",
        "        \"100010001\",\n",
        "        \"001110000\",\n",
        "        \"010010100\",\n",
        "        \"100010010\",\n",
        "        \"000110001\",\n",
        "        \"000011100\",\n",
        "        \"001010010\",\n",
        "        \"010010001\",\n",
        "        \"100011000\",\n",
        "        \"010110000\",\n",
        "        \"100010100\",\n",
        "        \"000110010\",\n",
        "        \"000010101\",\n",
        "        \"000011010\",\n",
        "        \"001010001\",\n",
        "        \"010011000\",\n",
        "        \"101010000\",\n",
        "    ]\n",
        "    masks = []\n",
        "    masks_n = []\n",
        "\n",
        "    # make masks\n",
        "    for mask_bin in masks_origin:\n",
        "        m = []\n",
        "        s = 0\n",
        "        for ch in mask_bin:\n",
        "            m.append(int(ch))\n",
        "            if int(ch) == 1:\n",
        "                s += 1   \n",
        "                            \n",
        "        masks.append(np.array(m).reshape((3, 3)))\n",
        "        masks_n.append(s)\n",
        "\n",
        "    height, width = img.shape\n",
        "\n",
        "    a = patchify(img, (3, 3))\n",
        "    a = a.reshape(\n",
        "        (height - 2) * (width - 2), 3, 3\n",
        "    )  # (x-2, y-2, 3) -> ((x-2)*(y-2), 3, 3)\n",
        "\n",
        "    ret = []\n",
        "    for mask, n in zip(masks, masks_n):\n",
        "        res = np.logical_and(mask, a)\n",
        "        logic = np.sum(np.sum(res, axis=2), axis=1)\n",
        "        ret.append(np.sum(logic == n))\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "def patchify(img, patch_shape):\n",
        "    img = np.ascontiguousarray(img)  # won't make a copy if not needed\n",
        "    X, Y = img.shape\n",
        "    x, y = patch_shape\n",
        "    shape = ((X - x + 1), (Y - y + 1), x, y)  # number of patches, patch_shape\n",
        "    # The right strides can be thought by:\n",
        "    # 1) Thinking of `img` as a chunk of memory in C order\n",
        "    # 2) Asking how many items through that chunk of memory are needed when indices\n",
        "    #    i,j,k,l are incremented by one\n",
        "    strides = img.itemsize * np.array([Y, 1, Y, 1])\n",
        "    return np.lib.stride_tricks.as_strided(img, shape=shape, strides=strides)"
      ],
      "metadata": {
        "id": "UTDx6Q6qh8nw"
      },
      "id": "UTDx6Q6qh8nw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GABOR"
      ],
      "metadata": {
        "id": "fykjrxzelZoi"
      },
      "id": "fykjrxzelZoi"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from scipy import misc\n",
        "import scipy.io as sio\n",
        "from skimage.color import rgb2gray\n",
        "def get_gabor(image):\n",
        "    \n",
        "    input_img = image\n",
        "    if input_img.ndim == 3 and input_img.shape[-1] == 3:\n",
        "        img = cv2.cvtColor(input_img,cv2.COLOR_BGR2GRAY)\n",
        "    elif input_img.ndim == 2:\n",
        "        img = input_img\n",
        "    else:\n",
        "        raise Exception(\"The module works only with grayscale and RGB images!\")\n",
        "    pixel_values = image.reshape(-1)\n",
        "    Pixel_Value = pixel_values   #Pixel value itself as a feature\n",
        "    #df['Image_Name'] = image   #Capture image name as we read multiple images\n",
        "    num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
        "    kernels = []  #Create empty list to hold all kernels that we will generate in a loop\n",
        "    for theta in range(8):   #Define number of thetas. Here only 2 theta values 0 and 1/4 . pi \n",
        "        theta = theta / 4. * np.pi\n",
        "        for sigma in (1, 3,):  #Sigma with values of 1 and 3\n",
        "            for lamda in np.arange(0, np.pi, np.pi / 4):   #Range of wavelengths\n",
        "                for gamma in (0.05, 0.5):   #Gamma values of 0.05 and 0.5\n",
        "                           \n",
        "                    gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
        "#                   print(gabor_label)\n",
        "                    ksize=9  #Try 15 for hidden image. Or 9 for others\n",
        "                    phi = 0  #0.8 for hidden image. Otherwise leave it to 0\n",
        "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)    \n",
        "                    kernels.append(kernel)\n",
        "                    #Now filter the image and add values to a new column \n",
        "                    fimg = cv2.filter2D(image, cv2.CV_8UC3, kernel)                \n",
        "                    filtered_img = fimg.reshape(-1)\n",
        "                \n",
        "                    gabor_label = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
        "                    #print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
        "                    num += 1  #Increment for gabor column label\n",
        "    return gabor_label"
      ],
      "metadata": {
        "id": "ferxZyIilZPT"
      },
      "id": "ferxZyIilZPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_HOG,labels_HOG = feat_lab_HOG(imagePaths)\n",
        "features_LAND,labels_LAND = feat_lab_LAND(imagePaths)\n",
        "features_LBP,labels_LBP = feat_lab_LBP(imagePaths)\n",
        "features_HLAC,labels_HLAC = feat_lab_HLAC(imagePaths)\n",
        "features_GABOR,labels_GABOR = feat_lab_GABOR(imagePaths) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-8vh5-lennf",
        "outputId": "b493aa82-de91-4fd2-c0e6-070215d289b9"
      },
      "id": "l-8vh5-lennf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LAND: \",features_LAND)\n",
        "print(\"HOG: \",features_HOG)\n",
        "print(\"LBP: \",features_LBP)\n",
        "print(\"HLAC: \",features_HLAC)\n",
        "print(\"GABOR\",features_GABOR)\n",
        "\n",
        "print(\"LAND: \",features_LAND.shape)\n",
        "print(\"HOG: \",features_HOG.shape)\n",
        "print(\"LBP: \",features_LBP.shape)\n",
        "print(\"HLAC: \",features_HLAC.shape)\n",
        "print(\"GABOR\",features_GABOR.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bapIjN8FhVzn",
        "outputId": "58f3e990-3b82-4978-a277-fecb86d4d801"
      },
      "id": "bapIjN8FhVzn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LAND:  [[-46.01492537 -13.07462687  47.83637972 ...  25.92537313  27.13602773\n",
            "  -74.82081183]\n",
            " [-44.71641791 -13.97014925  46.84787189 ...  27.02985075  28.72318938\n",
            "  -74.22801571]\n",
            " [-47.31343284 -17.02985075  50.28495544 ...  23.97014925  24.35515876\n",
            "  -77.79879082]\n",
            " ...\n",
            " [-44.1641791   -8.8358209   45.03938773 ...  30.1641791   31.00327665\n",
            "  -84.6394461 ]\n",
            " [-63.01492537 -19.43283582  65.94327811 ...  26.56716418  27.47768896\n",
            "  -70.2089151 ]\n",
            " [-50.3880597   -5.80597015  50.72145355 ...  29.19402985  30.11436211\n",
            "  -83.79846084]]\n",
            "HOG:  [[0.31295983 0.00451276 0.0014583  ... 0.0622666  0.08588023 0.29132184]\n",
            " [0.21357372 0.07510764 0.0083327  ... 0.00327694 0.06911241 0.3196029 ]\n",
            " [0.02762948 0.01551961 0.         ... 0.         0.00113458 0.0020454 ]\n",
            " ...\n",
            " [0.09654229 0.22587123 0.22587123 ... 0.01369306 0.04037822 0.18140746]\n",
            " [0.0218669  0.04179065 0.04890871 ... 0.02255598 0.02986664 0.01657264]\n",
            " [0.09487885 0.         0.         ... 0.03106328 0.17537065 0.28426754]]\n",
            "LBP:  [[[117.]\n",
            "  [  5.]\n",
            "  [ 69.]\n",
            "  ...\n",
            "  [ 90.]\n",
            "  [ 68.]\n",
            "  [658.]]\n",
            "\n",
            " [[218.]\n",
            "  [  9.]\n",
            "  [118.]\n",
            "  ...\n",
            "  [157.]\n",
            "  [ 76.]\n",
            "  [890.]]\n",
            "\n",
            " [[284.]\n",
            "  [ 25.]\n",
            "  [135.]\n",
            "  ...\n",
            "  [150.]\n",
            "  [ 77.]\n",
            "  [719.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[250.]\n",
            "  [ 26.]\n",
            "  [103.]\n",
            "  ...\n",
            "  [108.]\n",
            "  [ 53.]\n",
            "  [838.]]\n",
            "\n",
            " [[ 93.]\n",
            "  [  8.]\n",
            "  [ 64.]\n",
            "  ...\n",
            "  [ 89.]\n",
            "  [ 67.]\n",
            "  [542.]]\n",
            "\n",
            " [[160.]\n",
            "  [  8.]\n",
            "  [ 66.]\n",
            "  ...\n",
            "  [121.]\n",
            "  [ 73.]\n",
            "  [462.]]]\n",
            "HLAC:  [[ 8472  8080  7936 ...  7627  7860  7626]\n",
            " [12934 12666 12605 ... 12445 12562 12382]\n",
            " [ 7915  7357  7199 ...  6750  7087  6745]\n",
            " ...\n",
            " [ 8740  8433  8158 ...  7876  8127  7863]\n",
            " [ 6421  6198  6090 ...  5880  6031  5891]\n",
            " [ 8852  8398  8239 ...  7929  8149  7901]]\n",
            "GABOR [[ 79  91  90 ...  95 104 107]\n",
            " [ 72  75  70 ...  43  46  49]\n",
            " [ 44  48  48 ...  15  15  12]\n",
            " ...\n",
            " [ 21  30  36 ...  13   6   0]\n",
            " [  0   3   5 ...  34  28  19]\n",
            " [ 76  74  80 ...  38  39  36]]\n",
            "LAND:  (44, 268)\n",
            "HOG:  (44, 18928)\n",
            "LBP:  (44, 256, 1)\n",
            "HLAC:  (44, 25)\n",
            "GABOR (44, 16384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE FILE ด้วย"
      ],
      "metadata": {
        "id": "YuCKPVSJ0mzh"
      },
      "id": "YuCKPVSJ0mzh"
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"features_HOG\", features_HOG)\n",
        "np.save(\"features_HLAC\", features_HLAC)\n",
        "np.save(\"features_LAND\", features_LAND)\n",
        "np.save(\"features_LBP\", features_LBP)\n",
        "np.save(\"features_GABOR\", features_GABOR)\n",
        "\n",
        "np.save(\"labels_HOG\", labels_HOG)\n",
        "np.save(\"labels_HLAC\", labels_HLAC)\n",
        "np.save(\"labels_LAND\", labels_LAND)\n",
        "np.save(\"labels_LBP\", labels_LBP)\n",
        "np.save(\"labels_GABOR\", labels_GABOR)"
      ],
      "metadata": {
        "id": "WqnlbL59yEMm"
      },
      "id": "WqnlbL59yEMm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}